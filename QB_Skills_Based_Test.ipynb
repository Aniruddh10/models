{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json #library needed\n",
    "import pandas as pd#library needed\n",
    "with open('C:/Users/hp/Desktop/Final/1.QB_Skills_Based_Test/questions.json',encoding='utf-8') as jsonfile:#here the json file should be dynamic(BACKEND AND AIML)\n",
    "    data = json.load(jsonfile,)#json files data is stored in data\n",
    "master_frame1=[]#important\n",
    "#-------------------------------------------------Please go to main part before going to functions---------------------------------------------------------------------------------------------------------\n",
    "def getmcq(a,difficulty,id1,number):#parameters taken a=no of skills entered by user.difficulty=difficulty of assigned test,id1=the id of the user,number=no. of questions to be given for test\n",
    "    #global question_list\n",
    "    global master_frame1 #important\n",
    "    generic=10#no of generic questions which will come to all the Users\n",
    "    if(number%a==0):#eg for 30(number) questions if 1,2,3,5 number of skills are entered then no of questions will be divided equally among the skills\n",
    "        no_of_questions=int(number/a)#no of questions for each skill will be 30question(for 1 skill),15(for 2 skills),10(for 3 skills) etc..\n",
    "        l2=[no_of_questions for i in range(a)]#list of particular skill having particular number of questions\n",
    "        #l2 is a list of how many number of questions will be divided upon each topic.In this case all topics will get equal number of questions\n",
    "        #list_of_files=[]\n",
    "        list_of_dataframes=[]\n",
    "        list_of_dataframes1=[]\n",
    "        df=pd.read_json(\"C:/Users/hp/Desktop/Final/1.QB_Skills_Based_Test/\"+ \"PYM\" +\".json\",encoding='latin1')#file is retreived(Backend and AIML)\n",
    "        for i in range(a):#loop for the total number of skills\n",
    "            #df = pd.read_csv(\"C:/Users/hp/Desktop/Final/1.QB_Skills_Based_Test/\"+ \"PYM\" +\".csv\",encoding='latin1',error_bad_lines=False)#file is retreived(Backend and AIML)\n",
    "            \n",
    "            #print(df6)\n",
    "            df1=df[df['difficulty'].str.contains(difficulty,na=False)]#question filter for difficulty\n",
    "            df2=df1[df1['topic'].str.contains(list1[i])]#dataframe will contain only that particular topic questions\n",
    "            df3=df2.sample(n =l2[i], replace = True) #question filter for no of questions retreived and random retreival ,l2[i] is the list where the no.of questions assigned for that particular skill are stored\n",
    "            #Imp replace=True will allow duplicate entries as dataset is small #for non duplicate entries do replace=False\n",
    "            list_of_dataframes.append(df3)#all the questions till the loop ends will be appended in the list_of_dataframes \n",
    "        df4=df[df['topic'].str.contains(\"generic\")]#question filter for generic questions topic    \n",
    "        df5=df4.sample(n =10, replace = True)#10 questions of generic type will be fetched\n",
    "        list_of_dataframes.append(df5)#this will also be appended to the above list_of_dataframes\n",
    "        master_frame=pd.concat(list_of_dataframes,axis=0,ignore_index=True)#all skill questions are received and put in one master frame\n",
    "        master_frame1=master_frame[['QID']]#master frame1 will fetch the qids of the questions given in master_frame\n",
    "        list_of_dataframes1.append(master_frame1)#important\n",
    "        master_df=pd.concat(list_of_dataframes1,axis=0,ignore_index=True)#here all the dataframes are joined in a master_df#important\n",
    "        master_df.reset_index(inplace=True)#important\n",
    "        master_df.to_json(r\"C:/Users/hp/Desktop/Final/1.QB_Skills_Based_Test\"+id1+\".json\")#the qids are stored in a locally made json path with the name of the json file given by the id(parameter)\n",
    "        #^important(Backend and AIML Team)\n",
    "        \n",
    "    else:#condition where no of questions is not being exactly divided by no of skills\n",
    "        no_of_questions=number//a  # eg for 4 skills and 30 questions.This will be for if user enters 4 skills then 2 skills will have 8 questions each and 2 will have 7 questgions\n",
    "        extra_questions=number%a#the no of extra questions which have not been properly divided\n",
    "        l2=[no_of_questions for i in range(a)]#list to store equal no of questions for eack skill\n",
    "        for i in range(0,extra_questions):#logic to store some extra questions in some of the skills\n",
    "            l2[i]=no_of_questions+1#important\n",
    "        list_of_files=[]#important\n",
    "        list_of_dataframes=[]#important\n",
    "        list_of_dataframes1=[]#important\n",
    "        df=pd.read_json(\"C:/Users/hp/Desktop/Final/1.QB_Skills_Based_Test/\"+ \"PYM\" +\".json\",encoding='latin1')#file is retreived(Backend and AIML)\n",
    "        for i in range(a): #Same as above scenario\n",
    "            #df = pd.read_csv(\"C:/Users/hp/Desktop/Final/1.QB_Skills_Based_Test/\"+ \"PYM\" +\".csv\",encoding='latin1',error_bad_lines=False)#file is retreived(Backend and AIML)\n",
    "            \n",
    "            #print(df6)\n",
    "            #We will get questions from here\n",
    "            df1=df[df['difficulty'].str.contains(difficulty,na=False)]#question filter for easy\n",
    "            #print(df1)\n",
    "            df2=df1[df1['topic'].str.contains(list1[i])]\n",
    "            #print(df2)\n",
    "            df3=df2.sample(n =l2[i], replace = True) #question filter for no of questions retreived and random retreival\n",
    "            #print(df5)\n",
    "            list_of_dataframes.append(df3)\n",
    "            \n",
    "        df4=df[df['topic'].str.contains(\"generic\")]    \n",
    "        df5=df4.sample(n =10, replace = True)\n",
    "        list_of_dataframes.append(df5)\n",
    "        master_frame=pd.concat(list_of_dataframes,axis=0,ignore_index=True)\n",
    "        master_frame1=master_frame[['QID']]\n",
    "        list_of_dataframes1.append(master_frame1)\n",
    "        master_df=pd.concat(list_of_dataframes1,axis=0,ignore_index=True)\n",
    "        master_df.reset_index(inplace=True)\n",
    "        #print(\"Hello\")\n",
    "        #print(id1)\n",
    "        master_df.to_json(r\"C:/Users/hp/Desktop/Final/1.QB_Skills_Based_Test/\"+id1+\".json\")\n",
    "        #print(\"Hello\")\n",
    "#------------------------------------------------------------Main Part----------------------------------------------------------------\n",
    "#no_of_questions=int(input(\"enter no of questions\"))#JSON NEEDED(Backend and AIML) Variable name no_of_questions should not be changed\n",
    "no_of_questions=int(data['no_of_questions'])\n",
    "id2=data['user_id']#user id from the json file questions.json\n",
    "skill=data['total_skills']#total skills from questions.json\n",
    "category=data['category']#JSON INPUT NEEDED(Out of 4 types-NonIT Student,IT Student,IT Professional,NonIT Professional)\n",
    "skill1=data['skill_name1']#skill 1 from questions.json\n",
    "skill2=data['skill_name2']#skill 2 from questions.json\n",
    "skill3=data['skill_name3']#skill 3 from questions.json\n",
    "skill4=data['skill_name4']#skill 4 from questions.json\n",
    "skill5=data['skill_name5']#skill 5 from questions.json\n",
    "list1=[skill1,skill2,skill3,skill4,skill5]#list of all the skills\n",
    "difficulty=\"easy\"#default difficulty easy\n",
    "if(category==\"IT Professional\" or category==\"IT Student\"):#AIML (here IT Professional/IT Student should come)\n",
    "    prof=int(data[\"skill_prof\"])#proficiency of user in that particular skill\n",
    "    if(prof>2 and prof<4):#condition for difficulty\n",
    "        difficulty=\"medium\"\n",
    "    if(prof>=4):#condition for difficulty\n",
    "        difficulty=\"hard\"\n",
    "    \n",
    "getmcq(skill,difficulty,id2,no_of_questions) # the getmcq function is called\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
